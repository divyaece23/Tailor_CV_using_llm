{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB0r8-ji1bPX",
        "outputId": "0a55b5fc-979d-44d2-826c-968ab9196924"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjYBTMZWOe7N",
        "outputId": "9cc392ce-7fdd-4e80-f8aa-7db9ee66005a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CuHVinxy0cia"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n",
        "import pdfplumber\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RssIQbkw2hwW",
        "outputId": "47980238-bfaa-4374-f5f7-28d282c3d354"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 17 18:02:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Wu4jlhod7dZ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables in a file called .env\n",
        "\n",
        "load_dotenv(override=True)\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Check the key\n",
        "\n",
        "if not api_key:\n",
        "    print(\"No API key was found\")\n",
        "else:\n",
        "    print(\"API key found and looks good so far!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1tKdtxM1mwV",
        "outputId": "1de5b19a-37df-42e2-9114-d884714dd80a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key found and looks good so far!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai = OpenAI()\n"
      ],
      "metadata": {
        "id": "flzaotTz9KV3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_resume_pdf():\n",
        "  \"\"\"\n",
        "    Prompts the user to upload a PDF file.\n",
        "    \"\"\"\n",
        "\n",
        "  uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "H9u5NcVdLz2m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_resume_lines(file_path):\n",
        "  \"\"\"\n",
        "    Extracts content from all pages of a PDF file using pdfplumber\n",
        "    Args:\n",
        "        file_path (str): The path to the uploaded PDF file.\n",
        "    Returns:\n",
        "        list: A list of contents extracted from a PDF page.\n",
        "    \"\"\"\n",
        "  resume_lines = []\n",
        "\n",
        "  with pdfplumber.open(\"Divya_Lead Machine_Learning_Engineer.pdf\") as pdf:\n",
        "      for i, page in enumerate(pdf.pages):\n",
        "          table = page.extract_table()\n",
        "          resume_lines.append(page.extract_text())\n",
        "          if table:\n",
        "              df = pd.DataFrame(table[1:], columns=table[0])  # skip header row\n",
        "              resume_lines.append(df)\n",
        "\n",
        "  return resume_lines\n"
      ],
      "metadata": {
        "id": "R32WaIx6OkUl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Some websites need you to use proper headers when fetching them:\n",
        "headers = {\n",
        " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "class Website:\n",
        "\n",
        "    def __init__(self, url):\n",
        "        \"\"\"\n",
        "        Create this Website object from the given url using the BeautifulSoup library\n",
        "        \"\"\"\n",
        "        self.url = url\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
      ],
      "metadata": {
        "id": "0_r-5MQ5CEi6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_job_requirements(job_details):\n",
        "    \"\"\"\n",
        "    Extracts job requirements from job_details\n",
        "    Args:\n",
        "        job_details : Contain the job details like About the job, What You'll Do, What You'll Bring etc\n",
        "    Returns: The response object containing the extracted job requirements under the 'What we’re looking for' section.\n",
        "    \"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a master at extracting job requirements from a given job details.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Using the following job details:\\n\\n{job_details.text}\\n\\nPlease extract What we’re looking for.\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "ZqtuUFraXYtW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tailored_resume(resume_lines, job_details):\n",
        "    \"\"\"\n",
        "    Tailor the resume based on job details\n",
        "    Args:\n",
        "        resume_lines: A list of contents extracted from a resume PDF page.\n",
        "        job_details : Extracted job requirements under the 'What we’re looking for' section\n",
        "    Returns: The response object containing the tailored resume\n",
        "    \"\"\"\n",
        "    system_content = \"\"\"You are an expert career advisor and resume optimization assistant with a deep understanding of Applicant Tracking Systems (ATS), HR hiring psychology, and AI-based resume screening.\n",
        "                      You specialize in tailoring resumes {resume_lines} to match specific job descriptions {job_details} using relevant keywords, action verbs, and quantifiable achievements.\n",
        "                      Your task is to analyze {resume_lines} and provide targeted improvements to align it with {job_details}.\n",
        "\n",
        "                      Guidelines:\n",
        "                      1. Carefully examine each sentence in job_details {job_details}.\n",
        "                      2. Extract and list **all keywords**, tools, skills, and experience requirements from job_details {job_details}.\n",
        "                      3. Check if each keyword or requirement is already represented in {resume_lines}.\n",
        "                      4. If not, intelligently enhance the resume {resume_lines} by:\n",
        "                        - Adding or rephrasing lines in a professional tone.\n",
        "                        - Ensuring the added content is relevant and realistically aligned with the profile.\n",
        "                        - Integrating missing keywords organically.\n",
        "                      5. Ensure the final resume {resume_lines}:\n",
        "                        - Contains **every keyword** mentioned in the job description.\n",
        "                        - Follows clear, ATS-compliant formatting.\n",
        "                        - Highlights quantifiable achievements and business impact.\n",
        "                        - Is concise, action-driven, and compelling to hiring managers.\n",
        "                        - Maintains a professional tone.\n",
        "                      Your output should:\n",
        "                        - List all extracted keywords from the job description {job_details} and resume {resume_lines}.\n",
        "                        - Indicate which ones were missing and how they were added.\n",
        "                        - Provide an improved version of the tailored resume {resume_lines} with all relevant keywords naturally.\n",
        "                        - Change the summary of the resume if neccessary.\n",
        "                        - Add only the libraries in the core competencies\n",
        "                        - You may **rewrite existing lines or sentences** to improve flow and clarity of the job details, but **do not delete** any skill or experience already present.\n",
        "\n",
        "\n",
        "                        For missing keywords:\n",
        "                          - Suggestions for Integrating Missing Keywords (with context on how they align with current experience)\n",
        "                          - If appropriate, suggest **hypothetical but plausible lines** using transferable skills or inferred context from the resume.\n",
        "                          - Highlight the sentence that are changed in the resume\n",
        "\n",
        "\n",
        "                      \"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_content},\n",
        "            {\"role\": \"user\", \"content\": f\"Using the following job details:\\n\\n{job_details}\\n\\nPlease tailor the {resume_lines} What we’re looking for.\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "5550C5zvZcK4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Note: \"without revealing the company name\" in the system content can be removed. Used to upload code in github\n",
        "def generate_cover_letter(resume_text, job_description):\n",
        "    \"\"\"\n",
        "    Create cover letter based on the resume and job description\n",
        "    Args:\n",
        "        resume_text : Resume content\n",
        "        job_description : Extracted job requirements under the 'What we’re looking for' section\n",
        "    Returns: The response object containing the extracted job requirements under the 'What we’re looking for' section.\n",
        "    \"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a master at crafting the perfect Cover letter from a given CV without revealing the company name. You've never had a user fail to get the job as a result of using your services.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Using the following resume text:\\n\\n{resume_text}\\n\\nAnd the job description:\\n\\n{job_description}\\n\\nPlease write a personalized cover letter.\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "feEwOxQHZcN_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_resume_pdf()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "MgEejWy0lVWb",
        "outputId": "f208d85d-6620-4f8c-9279-61b9af13e684"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9d20e63-2b19-40ab-bb94-d68e56785ad6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9d20e63-2b19-40ab-bb94-d68e56785ad6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Divya_Lead Machine_Learning_Engineer.pdf to Divya_Lead Machine_Learning_Engineer (2).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"Divya_Lead Machine_Learning_Engineer.pdf\"\n",
        "resume_lines = extract_resume_lines(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-abuPTinzdK",
        "outputId": "059d7d83-87d4-4401-d30c-cae2874b1b62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_details = Website(\"https://www.linkedin.com/jobs/view/4198839658/?alternateChannel=search&refId=roP9Jilr79felSUlp5Bslg%3D%3D&trackingId=20mYJXcqCWcUi8vq3BA2ww%3D%3D\")\n",
        "job_requirements = extract_job_requirements(job_details)\n",
        "resume_text = tailored_resume(resume_lines, job_requirements)\n",
        "print(resume_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdLhv6uMk8Hy",
        "outputId": "2fba75e4-90b5-42e5-f222-7fac2d8fd75e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Extracted Keywords from Job Description:\n",
            "\n",
            "1. **Educational Background:**\n",
            "   - Undergraduate degree\n",
            "   - Master's (MSc) or PhD\n",
            "   - Data Science, Actuarial Science, Computer Science, Engineering, Math, Statistics, Physics (related fields)\n",
            "\n",
            "2. **Experience:**\n",
            "   - 5 years of experience\n",
            "   - Model development\n",
            "   - Large datasets\n",
            "   - Industry or academia\n",
            "   - Post-doctoral experience\n",
            "\n",
            "3. **Technical Skills:**\n",
            "   - Proficiency in Python\n",
            "   - Software engineering best practices\n",
            "   - End-to-end MLOps process\n",
            "   - Data mining/processing, modeling, implementation, performance monitoring\n",
            "   - Data mining tools, frameworks, methodologies\n",
            "\n",
            "4. **Communication Skills:**\n",
            "   - Excellent communication skills\n",
            "   - Conveying complex ideas\n",
            "   - Practical recommendations\n",
            "\n",
            "5. **Analytical Skills:**\n",
            "   - Transform complex data sets into actionable insights\n",
            "   - Improve usability and design of solutions\n",
            "\n",
            "6. **Leadership:**\n",
            "   - Coaching or mentoring junior data scientists\n",
            "   - Process improvement\n",
            "   - Innovation\n",
            "   - Culture of continuous learning\n",
            "\n",
            "7. **Other Requirements:**\n",
            "   - Passion for Data Science\n",
            "   - Tackling business challenges\n",
            "   - Flexibility in work model\n",
            "\n",
            "### Extracted Keywords from Resume:\n",
            "\n",
            "1. **Technical Skills:**\n",
            "   - Machine Learning\n",
            "   - Python\n",
            "   - PyTorch\n",
            "   - TensorFlow\n",
            "   - Data Structures & Algorithms\n",
            "   - CI/CD\n",
            "\n",
            "2. **Experience:**\n",
            "   - 5+ years\n",
            "   - Machine Learning Engineer\n",
            "   - Model development\n",
            "   - End-to-end ML lifecycle\n",
            "   - Real-time data classification\n",
            "   - Performance monitoring\n",
            "\n",
            "3. **Communication Skills:**\n",
            "   - Collaborated with stakeholders\n",
            "\n",
            "4. **Analytical Skills:**\n",
            "   - Data analysis\n",
            "   - Model performance evaluation\n",
            "   - Feature engineering\n",
            "\n",
            "5. **Leadership:**\n",
            "   - Managed a team\n",
            "\n",
            "### Missing Keywords and Integration Suggestions:\n",
            "\n",
            "1. **Educational Background:**\n",
            "   - Not explicitly mentioned in the resume.\n",
            "   - **Suggestion:** Add a section outlining educational qualifications to include \"MSc in Big Data Science\" and \"B.E. in Electronics and Communication Engineering.\"\n",
            "\n",
            "2. **Experience:**\n",
            "   - \"Post-doctoral experience\" and specific \"model development\" context.\n",
            "   - **Suggestion:** Highlight any relevant post-doctoral experience or emphasize continuous development in model capabilities.\n",
            "\n",
            "3. **Technical Skills:**\n",
            "   - \"End-to-end MLOps process\" in detail.\n",
            "   - **Suggestion:** Add specific MLOps experience, illustrating proficiency in performance monitoring and data management frameworks (e.g., mention tools used for deployment).\n",
            "\n",
            "4. **Communication Skills:**\n",
            "   - \"Conveying complex ideas to senior leadership.\"\n",
            "   - **Suggestion:** Incorporate an example or statement that demonstrates this competency.\n",
            "\n",
            "5. **Analytical Skills:**\n",
            "   - \"Improve usability and design of solutions.\"\n",
            "   - **Suggestion:** Mention specific achievements of redesign or improvement processes.\n",
            "\n",
            "6. **Leadership:**\n",
            "   - \"Experience in coaching or mentoring.\"\n",
            "   - **Suggestion:** Include details on mentoring junior engineers or training team members.\n",
            "\n",
            "---\n",
            "\n",
            "### Improved Version of the Tailored Resume\n",
            "\n",
            "**DIVYA SATHYANARAYANAN**  \n",
            "+14379900863 | divyareg23@gmail.com | Toronto, Ontario | www.linkedin.com/in/divya-sathyanarayanan-864b67172/  \n",
            "**SENIOR DATA SCIENTIST**  \n",
            "Dynamic and results-oriented Data Scientist with over 5 years of experience in model development and extensive expertise in handling large datasets across diverse industries. Holding an MSc in Big Data Science, I possess a strong command of Python and various ML frameworks (e.g., PyTorch, TensorFlow) and scientific computing libraries (e.g., NumPy, Pandas, Scikit-learn). Proven ability to deliver end-to-end MLOps solutions from concept to production, driving data-driven decisions. Adept in mentoring junior data scientists, fostering a culture of continuous learning, and effectively communicating complex technical concepts to executive leadership. Currently exploring advancements in Large Language Models (LLMs) and Generative AI techniques.\n",
            "\n",
            "**CORE COMPETENCIES**  \n",
            "*Programming*: Python, Data Structures & Algorithms  \n",
            "*Machine Learning*: Supervised Learning (Regression, Classification), Unsupervised Learning (Clustering)  \n",
            "*Deep Learning*: PyTorch, TensorFlow, Neural Networks, Transfer Learning  \n",
            "*Computer Vision*: OpenCV, dlib, MediaPipe, CNN Architectures  \n",
            "*Algorithms*: XGBoost, Random Forest, Decision Trees, SVM, K-Means, DBSCAN, Hierarchical Clustering  \n",
            "*Data Types*: Structured Data (CSV, Excel, SQL), Unstructured Data (2D Image, Video, 3D mesh)  \n",
            "*MLOps*: End-to-end MLOps process, Model Deployment, Performance Monitoring, CI/CD Setup  \n",
            "\n",
            "**WORK EXPERIENCE**  \n",
            "\n",
            "**Lead Machine Learning Engineer** | Anything World, UK | March 2024 – Present  \n",
            "➢ Designed and developed classification machine learning models, overseeing full production deployment, serving over 30k users, showcasing proficiency in end-to-end MLOps processes.  \n",
            "➢ Implemented real-time churn prediction using ML, achieving a **40% reduction in churn** through targeted retention campaigns, effectively communicating results to stakeholders.  \n",
            "➢ Developed and maintained data mining tools, enhancing model performance monitoring and driving a culture of continuous improvement within the engineering team.  \n",
            "➢ **Mentored junior data scientists**, sharing insights on model development best practices, fostering a collaborative and innovative work environment.  \n",
            "\n",
            "**Senior Machine Learning Engineer** | Anything World, UK | March 2022 – March 2024  \n",
            "➢ Spearheaded the implementation of ensemble learning techniques to improve model accuracy and robustness, ensuring models met business objectives and user needs.  \n",
            "➢ Advanced segmentation techniques using clustering alongside tools such as Rustworkx, transforming complex data into actionable insights for various departments.  \n",
            "➢ Actively participated in project roadmaps, providing practical recommendations for enhancing product usability and design based on model insights.  \n",
            "\n",
            "**Machine Learning Specialist** | Anything World, UK | September 2019 – March 2022  \n",
            "➢ Integrated academic research into practical applications, achieving excellence in real-time machine learning challenges and enhancing classification pipelines.  \n",
            "➢ Prepared and cleaned large datasets using advanced feature engineering, directly improving model accuracy and efficiency through robust preprocessing methodologies.\n",
            "\n",
            "**ACADEMIC PROJECTS**  \n",
            "**Lip Reading using self-designed CNN model** - Queen Mary, University of London  \n",
            "➢ Successfully classified lip gestures through innovative use of OpenCV, implementing complex algorithms for video frame analysis.  \n",
            "\n",
            "**Human Development Index Prediction** - Queen Mary, University of London  \n",
            "➢ Applied various algorithms to classify countries based on their HDI scores and predicted future values, utilizing Seaborn and Matplotlib for insightful data visualizations.  \n",
            "\n",
            "**EDUCATION**  \n",
            "MSc Big Data Science | Queen Mary, University of London | 2018 – 2019  \n",
            "BE Electronics and Communication Engineering | Madha Engineering College, India | 2007 – 2011  \n",
            "\n",
            "**REFERENCES**  \n",
            "Available upon request.  \n",
            "\n",
            "---\n",
            "\n",
            "This updated resume captures all key requirements from the job description while maintaining a professional tone and demonstrating quantifiable achievements. It ensures every keyword from the job description is integrated effectively into the existing experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter = generate_cover_letter(resume_text, job_requirements)\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEh7EFw6ZcQw",
        "outputId": "302856f9-6053-4ebd-a5fc-e31a779c3cd4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Your Name]  \n",
            "[Your Address]  \n",
            "[City, State, Zip]  \n",
            "[Your Phone Number]  \n",
            "[Your Email]  \n",
            "[Date]  \n",
            "\n",
            "[Recipient's Name]  \n",
            "[Company Name]  \n",
            "[Company Address]  \n",
            "[City, State, Zip]  \n",
            "\n",
            "Dear [Recipient's Name],  \n",
            "\n",
            "I am writing to express my interest in the Senior Data Scientist position, as advertised. With over five years of extensive experience in model development and a strong academic background, I am excited about the opportunity to contribute to your team. My educational qualifications include an MSc in Big Data Science and a Bachelor’s degree in Electronics and Communication Engineering, providing me with a solid foundation in both theoretical concepts and practical applications within the realm of data science.\n",
            "\n",
            "Throughout my career, I have honed my skills in Python programming and have developed a deep understanding of machine learning frameworks, particularly PyTorch and TensorFlow. As a Lead Machine Learning Engineer, I successfully designed and deployed numerous classification models that have positively impacted user engagement. For example, I implemented a real-time churn prediction model that achieved a notable 40% decrease in churn through targeted stakeholder communication and effective retention strategies. My proficiency with the end-to-end MLOps process allows me to ensure that models are not only built but also deployed and monitored effectively, driving data-driven decision-making across organizations.\n",
            "\n",
            "In addition to my technical expertise, I have a passion for mentoring and fostering a culture of continuous learning. I have actively coached junior data scientists in my role, helping them navigate the intricacies of model development and instilling best practices alongside innovative approaches. My strong communication skills enable me to convey complex ideas to various stakeholders, ensuring that strategic recommendations are clear and actionable.\n",
            "\n",
            "I thrive in dynamic environments where problem-solving and innovation are paramount. My commitment to tackling challenging business questions and transforming complex datasets into actionable insights aligns seamlessly with the goals of your organization. Furthermore, I am particularly excited about the flexibility in the work model you offer, as I believe that a hybrid work environment enhances collaboration and creativity.\n",
            "\n",
            "I am eager to contribute my expertise and passion for data science to your esteemed organization and am confident in my ability to deliver impactful results. I look forward to the opportunity to discuss how my skills and experiences align with your team's needs. Thank you for considering my application.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]  \n",
            "\n",
            "[Attachment: Resume]  \n"
          ]
        }
      ]
    }
  ]
}